{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoPHPW0HChRLO7LpjuYz6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavankumarUppar/DLL/blob/main/Program6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTY17wmk7wbT",
        "outputId": "96ee2aaf-6eb0-4179-f76b-bcdb0f5fc753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.0030\n",
            "Epoch [200/1000], Loss: 0.0011\n",
            "Epoch [300/1000], Loss: 0.0006\n",
            "Epoch [400/1000], Loss: 0.0004\n",
            "Epoch [500/1000], Loss: 0.0003\n",
            "Epoch [600/1000], Loss: 0.0002\n",
            "Epoch [700/1000], Loss: 0.0002\n",
            "Epoch [800/1000], Loss: 0.0001\n",
            "Epoch [900/1000], Loss: 0.0001\n",
            "Epoch [1000/1000], Loss: 0.0001\n",
            "Generated Text:\n",
            " Thithis r a. ou dathithis re wis oure is owis wis tampleplextample your wis Yown is cextexteplamplextextaceplexth Youre t ce t. own te th ca wn You owisan t. t da s texthitextatan t t s thisampla s damplatampla. this rexte s text. s is yowisa. repla. you ampla. our texthitan amplat is isa. yown texthitexteple re tacamplacan yowite da damplext. th t ate Yowis own this is is ta. te Yown Yown thith text da You this acaca an t. th t. texte text. yourexte t. own da s ita You is rexta Your ite t. You y\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# Example text data (replace this with your own text data)\n",
        "text = \"This is an example text for generating text using LSTM in PyTorch. You can replace this with your own text data.\"\n",
        "\n",
        "# Preprocess the text and create character mappings\n",
        "all_characters = string.printable  # All printable ASCII characters\n",
        "char_to_index = {ch: i for i, ch in enumerate(all_characters)}\n",
        "index_to_char = {i: ch for i, ch in enumerate(all_characters)}\n",
        "num_characters = len(all_characters)\n",
        "\n",
        "# Convert text to a sequence of indices\n",
        "text_indices = [char_to_index[ch] for ch in text]\n",
        "\n",
        "# Create input-target pairs\n",
        "input_indices = text_indices[:-1]\n",
        "target_indices = text_indices[1:]\n",
        "\n",
        "# Convert input and target to tensors\n",
        "input_tensor = torch.tensor(input_indices, dtype=torch.long).unsqueeze(0)\n",
        "target_tensor = torch.tensor(target_indices, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "# Define the LSTM-based text generation model\n",
        "class LSTMTextGenerator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMTextGenerator, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = num_characters  # Input size is the number of unique characters\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "learning_rate = 0.01\n",
        "num_epochs = 1000\n",
        "sequence_length = 100  # Length of sequence used for training\n",
        "\n",
        "# Instantiate the model, define loss function and optimizer\n",
        "model = LSTMTextGenerator(input_size, hidden_size, num_layers, input_size)  # Output size = input size\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    hidden = model.init_hidden(1)  # Batch size = 1 for text generation\n",
        "    total_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output, hidden = model(input_tensor, hidden)\n",
        "    loss = criterion(output.squeeze(0), target_tensor.squeeze(0))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "# Sample text data\n",
        "text = \"This is a sample text. You can replace this with your own text data.\"\n",
        "def generate_text(start_letter='T', length=500):\n",
        "    generated_text = start_letter\n",
        "    current_letter = start_letter\n",
        "\n",
        "    for i in range(length):\n",
        "        next_chars = [text[idx + 1] for idx, char in enumerate(text) if char == current_letter and idx + 1 < len(text)]\n",
        "        if not next_chars:\n",
        "            break\n",
        "        next_letter = random.choice(next_chars)\n",
        "        generated_text += next_letter\n",
        "        current_letter = next_letter\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Generating text using the function\n",
        "generated_text = generate_text(start_letter='T', length=500)\n",
        "print(\"Generated Text:\\n\", generated_text)\n",
        "\n",
        "\n",
        "\n",
        "def generate_text(model, start_letter='T', length=500):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        hidden = model.init_hidden(1)\n",
        "        input_letter = start_letter\n",
        "        generated_text = input_letter\n",
        "\n",
        "        for i in range(length):\n",
        "            input_tensor = torch.tensor([[char_to_index[input_letter]]], dtype=torch.long)\n",
        "            output, hidden = model(input_tensor, hidden)\n",
        "            output_probabilities = nn.functional.softmax(output.squeeze(0), dim=0).detach().numpy()\n",
        "            predicted_index = np.argmax(output_probabilities)\n",
        "            predicted_char = index_to_char[predicted_index]\n",
        "            generated_text += predicted_char\n",
        "            input_letter = predicted_char\n",
        "\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fVNuEJKD76as"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}